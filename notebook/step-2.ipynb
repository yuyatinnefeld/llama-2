{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ae87262-bf35-4874-9cb3-9e654a4564de",
   "metadata": {},
   "source": [
    "# Login HuggingFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "105c37a2-1c41-46b6-a9d4-3c25da5564ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8bc47bbc0984762a4833e993614b431",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "416b7bf1-c0d3-40f0-b136-db90a1fec606",
   "metadata": {},
   "source": [
    "# Download Llama-2 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac69aae6-ee33-4758-b707-15c467faff12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "158871c6-26a4-4cfb-8240-c02ff2dc6caf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fb2546d67824162a0b9c9cce1777015",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "MODEL_NAME=\"meta-llama/Llama-2-7b-chat-hf\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "    \n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    low_cpu_mem_usage=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e5e1091-b354-421e-90b0-632a4d6782b1",
   "metadata": {},
   "source": [
    "# Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "afc191bf-0849-427f-be28-5310acdec05d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter:  what is the love?\n",
      "Enter length:  20\n"
     ]
    }
   ],
   "source": [
    "prompt = input('Enter: ')\n",
    "input_token_length = input('Enter length: ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "87d3c486-a67b-45fd-b077-da9cb9185500",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_input_prompt(tokenizer, prompt):\n",
    "    \n",
    "    inputs = tokenizer.encode(\n",
    "        prompt,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "    print(\"ðŸ¦™ðŸ’¬ Llama-2 Prompt Setup âœ…\")\n",
    "\n",
    "    return inputs, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bb3174a7-28ad-4ac5-90cc-8ea067c1ebc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ¦™ðŸ’¬ Llama-2 Prompt Setup âœ…\n"
     ]
    }
   ],
   "source": [
    "inputs, tokenizer = run_input_prompt(tokenizer, prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "70698798-e567-4c18-8957-30242a2a30b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_prompt_results(tokenizer, prompt, input_token_length):\n",
    "    print(\"ðŸ¦™ðŸ’¬ Llama-2 Prompt Result getting...\")\n",
    "    timeStart = time.time()\n",
    "    outputs = model.generate(\n",
    "        prompt,\n",
    "        max_new_tokens=int(input_token_length),\n",
    "    )\n",
    "\n",
    "    output_str = tokenizer.decode(outputs[0])\n",
    "\n",
    "    print(output_str)\n",
    "    print(\"ðŸ¦™ðŸ’¬ Llama-2 Prompt Output âœ…\")\n",
    "    print(\"Time taken: \", -timeStart + time.time())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15cf7873-6703-4bd2-934a-6175b2d56ff0",
   "metadata": {},
   "source": [
    "# Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "797e369d-d980-4a3e-9de3-5451f881fc07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ¦™ðŸ’¬ Llama-2 Prompt Result getting...\n",
      "<s> what is the love?\n",
      "\n",
      "Love is a complex and multifaceted emotion that can be difficult to\n",
      "ðŸ¦™ðŸ’¬ Llama-2 Prompt Output âœ…\n",
      "Time taken:  1636.2598598003387\n"
     ]
    }
   ],
   "source": [
    "generate_prompt_results(tokenizer, inputs, input_token_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e84cbf09-bb34-4cae-84b3-6f430d3fb90b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
